{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Dataset/train.csv')\n",
    "df_test = pd.read_csv('Dataset/test.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlist=df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_train=df_train[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "classes=columnlist[2:]\n",
    "label_train=df_train[classes]\n",
    "sentence_test=df_test[\"comment_text\"].fillna(\"CVxTz\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train=label_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize=text.Tokenizer(num_words=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(list(sentence_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=tokenize.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_train1=tokenize.texts_to_sequences(sentence_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_test1=tokenize.texts_to_sequences(sentence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_train=sequence.pad_sequences(sentence_train1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_test=sequence.pad_sequences(sentence_test1,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,X,Y=None,Transform=None):\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.Transform=Transform\n",
    "        if self.Transform is not None:\n",
    "            self.X=self.Transform(self.X)\n",
    "            if self.Y is not None:\n",
    "                self.Y=self.Transform(self.Y)\n",
    "        self.X=torch.from_numpy(self.X).long()\n",
    "        if self.Y is not None:\n",
    "            self.Y=torch.from_numpy(self.Y).float()\n",
    "    def __getitem__(self,idx):\n",
    "        data=self.X[idx]\n",
    "        if self.Y is not None:\n",
    "            label=self.Y[idx]\n",
    "            return data,label\n",
    "        return data\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set=CustomDataset(Input_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set=CustomDataset(Input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=torch.utils.data.DataLoader(Train_set,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=torch.utils.data.DataLoader(Test_set,batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pretrained_embedding(emb_file):\n",
    "    embedding_index={}\n",
    "    with open(emb_file,encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values=line.split()\n",
    "            word=values[0]\n",
    "            vector=np.asarray(values[1:],dtype=\"float32\")\n",
    "            embedding_index[word]=vector\n",
    "    return embedding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index= Pretrained_embedding(\"Glove/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(word_index,embedding_ind):\n",
    "    embedding_matrix=np.zeros((len(word_index)+1,100))\n",
    "    for word,i in word_index.items():\n",
    "        embedding_vector=embedding_ind.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i]=embedding_vector\n",
    "    return embedding_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix=embedding(word_index,embedding_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding=nn.Embedding(num_embeddings=100000,embedding_dim=100)\n",
    "        self.embedding.weight.data=torch.Tensor(embedding_matrix)\n",
    "        self.lstm=nn.LSTM(100,50,1,batch_first=True,bidirectional=True)\n",
    "        self.hidden=(Variable(torch.zeros(2,1,50)),Variable(torch.zeros(2,1,50)))\n",
    "        self.maxpool=nn.MaxPool1d(20)\n",
    "        self.fc=nn.Linear(100,6)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x=self.embedding(x)\n",
    "        x,self.hidden=self.lstm(x)\n",
    "        x=self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x=self.fc(x)\n",
    "        x=self.sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    learnin1g_rate = 1e-4\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learnin1g_rate)\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(Train):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        y_pred = model(data)\n",
    "        loss = F.binary_cross_entropy(y_pred, target)\n",
    "        print(batch_idx,loss)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.7066, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1 tensor(0.7051, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2 tensor(0.7019, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "3 tensor(0.7018, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "4 tensor(0.6993, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "5 tensor(0.6978, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "6 tensor(0.6964, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "7 tensor(0.6946, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "8 tensor(0.6927, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "9 tensor(0.6911, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "10 tensor(0.6892, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "11 tensor(0.6880, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "12 tensor(0.6861, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "13 tensor(0.6844, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "14 tensor(0.6815, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "15 tensor(0.6802, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "16 tensor(0.6786, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "17 tensor(0.6776, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "18 tensor(0.6752, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "19 tensor(0.6740, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "20 tensor(0.6720, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "21 tensor(0.6704, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "22 tensor(0.6688, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "23 tensor(0.6661, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "24 tensor(0.6649, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "25 tensor(0.6630, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "26 tensor(0.6599, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "27 tensor(0.6586, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "28 tensor(0.6576, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "29 tensor(0.6563, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "30 tensor(0.6535, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "31 tensor(0.6523, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "32 tensor(0.6498, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "33 tensor(0.6465, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "34 tensor(0.6463, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "35 tensor(0.6441, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "36 tensor(0.6429, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "37 tensor(0.6410, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "38 tensor(0.6374, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "39 tensor(0.6365, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "40 tensor(0.6337, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "41 tensor(0.6317, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "42 tensor(0.6285, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "43 tensor(0.6279, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "44 tensor(0.6240, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "45 tensor(0.6230, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "46 tensor(0.6206, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "47 tensor(0.6190, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "48 tensor(0.6158, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "49 tensor(0.6142, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "50 tensor(0.6115, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "51 tensor(0.6072, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "52 tensor(0.6068, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "53 tensor(0.6042, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "54 tensor(0.6013, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "55 tensor(0.6008, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "56 tensor(0.5975, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "57 tensor(0.5968, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "58 tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "59 tensor(0.5883, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "60 tensor(0.5870, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "61 tensor(0.5820, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "62 tensor(0.5805, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "63 tensor(0.5792, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "64 tensor(0.5758, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "65 tensor(0.5718, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "66 tensor(0.5704, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "67 tensor(0.5674, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "68 tensor(0.5660, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "69 tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "70 tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "71 tensor(0.5590, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "72 tensor(0.5557, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "73 tensor(0.5531, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "74 tensor(0.5474, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "75 tensor(0.5445, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "76 tensor(0.5451, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "77 tensor(0.5394, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "78 tensor(0.5362, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "79 tensor(0.5317, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "80 tensor(0.5337, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "81 tensor(0.5255, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "82 tensor(0.5257, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "83 tensor(0.5254, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "84 tensor(0.5171, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "85 tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "86 tensor(0.5165, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "87 tensor(0.5084, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "88 tensor(0.5073, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "89 tensor(0.5040, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "90 tensor(0.4955, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "91 tensor(0.4945, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "92 tensor(0.4915, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "93 tensor(0.4894, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "94 tensor(0.4844, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "95 tensor(0.4856, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "96 tensor(0.4836, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "97 tensor(0.4763, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "98 tensor(0.4777, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "99 tensor(0.4781, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "100 tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "101 tensor(0.4729, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "102 tensor(0.4644, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "103 tensor(0.4637, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "104 tensor(0.4559, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "105 tensor(0.4523, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "106 tensor(0.4518, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "107 tensor(0.4482, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "108 tensor(0.4470, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "109 tensor(0.4436, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "110 tensor(0.4368, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "111 tensor(0.4387, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "112 tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "113 tensor(0.4332, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "114 tensor(0.4341, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "115 tensor(0.4198, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "116 tensor(0.4276, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "117 tensor(0.4218, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "118 tensor(0.4171, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "119 tensor(0.4156, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "120 tensor(0.4105, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "121 tensor(0.4136, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "122 tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "123 tensor(0.4038, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "124 tensor(0.4001, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "125 tensor(0.3990, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "126 tensor(0.3928, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "127 tensor(0.3907, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "128 tensor(0.3864, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "129 tensor(0.3867, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "130 tensor(0.3828, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "131 tensor(0.3814, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "132 tensor(0.3799, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "133 tensor(0.3819, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "134 tensor(0.3694, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "135 tensor(0.3668, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "136 tensor(0.3686, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "137 tensor(0.3574, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "138 tensor(0.3592, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "139 tensor(0.3566, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "140 tensor(0.3507, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "141 tensor(0.3553, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "142 tensor(0.3509, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "143 tensor(0.3465, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "144 tensor(0.3468, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "145 tensor(0.3369, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 tensor(0.3487, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "147 tensor(0.3391, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "148 tensor(0.3396, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "149 tensor(0.3358, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "150 tensor(0.3314, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "151 tensor(0.3296, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "152 tensor(0.3245, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "153 tensor(0.3228, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "154 tensor(0.3207, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "155 tensor(0.3216, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "156 tensor(0.3155, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "157 tensor(0.3243, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "158 tensor(0.3118, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "159 tensor(0.3109, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(100000, 100)\n",
       "  (lstm): LSTM(100, 50, batch_first=True, bidirectional=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=20, stride=20, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=100, out_features=6, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.1995e-02, -1.5313e-03,  2.4060e-02,  ..., -1.7251e-02,\n",
      "         -1.8546e-02,  1.0394e-02],\n",
      "        [-5.4732e-02, -2.2900e-01,  7.4086e-01,  ..., -1.4866e-01,\n",
      "          8.3834e-01,  2.8605e-01],\n",
      "        [-2.0581e-01,  6.6463e-02,  1.9934e-01,  ..., -3.9948e-01,\n",
      "          4.8838e-01, -1.4728e-01],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-7.5740e-02,  4.2109e-01,  7.7687e-01,  ...,  9.5977e-02,\n",
      "          1.6282e+00, -1.0819e-01],\n",
      "        [ 6.8997e-02, -3.1269e-01, -2.4092e-01,  ..., -6.3050e-02,\n",
      "          5.2090e-01,  4.5936e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0662, -0.0279, -0.0690,  ...,  0.0654,  0.0175, -0.1101],\n",
      "        [ 0.0688, -0.1073, -0.0432,  ...,  0.0892,  0.0414, -0.0525],\n",
      "        [ 0.0817,  0.0610,  0.0551,  ...,  0.0032,  0.1122, -0.0752],\n",
      "        ...,\n",
      "        [-0.0657,  0.0717,  0.0007,  ...,  0.0483, -0.0576, -0.0959],\n",
      "        [ 0.0631, -0.1102,  0.1165,  ...,  0.0670,  0.0895,  0.1172],\n",
      "        [ 0.0669, -0.0339, -0.0756,  ..., -0.0161,  0.0650, -0.0732]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0004,  0.1450,  0.1565,  ..., -0.0458,  0.0448, -0.0926],\n",
      "        [ 0.0390, -0.0488,  0.0749,  ...,  0.0477, -0.0530, -0.0239],\n",
      "        [ 0.0447, -0.0578, -0.0235,  ..., -0.0309, -0.0960, -0.1373],\n",
      "        ...,\n",
      "        [ 0.0129, -0.0128,  0.0651,  ...,  0.1184, -0.1154,  0.1403],\n",
      "        [-0.0999,  0.0805,  0.0280,  ..., -0.0796, -0.1322, -0.0433],\n",
      "        [-0.1052,  0.0873,  0.0219,  ...,  0.0398, -0.0370, -0.0399]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-3.7376e-02,  5.5718e-02,  3.7935e-04, -8.6916e-02, -1.8961e-02,\n",
      "         9.9190e-02,  4.7483e-02,  1.5727e-01, -1.4045e-01,  2.1024e-02,\n",
      "         1.1779e-01, -2.6077e-02,  1.1952e-01,  1.0260e-01, -2.5989e-02,\n",
      "         1.5109e-02,  2.8209e-02,  7.5333e-03,  1.1633e-01, -5.5450e-02,\n",
      "        -6.5288e-02, -1.0815e-01,  7.7307e-02, -7.0509e-02,  5.6606e-02,\n",
      "        -6.8504e-02,  2.2399e-02,  3.4594e-02,  1.5059e-01, -3.0965e-03,\n",
      "        -2.4062e-02, -3.2118e-02, -4.8558e-02,  6.4566e-02, -1.0821e-01,\n",
      "         2.2289e-02, -5.2181e-02,  1.2488e-01, -3.0260e-02, -5.8224e-02,\n",
      "        -9.3780e-02, -1.2117e-01,  7.2248e-02, -2.4524e-02,  8.1657e-02,\n",
      "         8.7859e-02, -3.9867e-02,  7.0452e-02,  4.9820e-03, -3.7109e-02,\n",
      "         1.0032e-01, -5.8215e-02,  2.2827e-02,  7.5645e-02,  2.0950e-02,\n",
      "         1.5299e-05, -1.4485e-01,  1.1598e-01,  1.3645e-03,  1.0362e-02,\n",
      "        -7.3314e-02,  1.6497e-02, -3.1931e-02,  1.2352e-01,  4.4934e-02,\n",
      "         1.2589e-01,  4.3048e-02,  1.5009e-01, -4.9527e-02,  4.7235e-02,\n",
      "         6.4916e-02,  4.4274e-02, -1.2786e-01,  1.7211e-02,  5.6297e-02,\n",
      "        -1.1895e-01,  2.0632e-03,  9.5187e-02,  1.1454e-01, -1.1110e-01,\n",
      "         9.8525e-02, -6.8110e-02,  7.4036e-02, -9.9703e-02, -9.3008e-02,\n",
      "         9.4320e-02,  1.0288e-01, -1.1709e-01, -6.7831e-02, -8.6601e-02,\n",
      "         5.6682e-02, -4.5057e-03, -1.5158e-02, -6.1015e-02,  6.3054e-02,\n",
      "        -6.9895e-02, -7.4108e-02, -8.1207e-04,  1.0145e-01,  6.1653e-02,\n",
      "        -7.9003e-03,  8.5044e-02, -1.1781e-01, -1.1748e-01,  1.2595e-01,\n",
      "        -1.9408e-02,  1.3512e-02,  8.5530e-02, -8.1331e-02,  7.3839e-02,\n",
      "         7.8418e-02, -6.4434e-02,  9.2668e-02,  1.2763e-01, -1.5731e-02,\n",
      "        -7.1328e-02, -6.8842e-02, -1.0692e-01, -7.9826e-02,  1.0814e-01,\n",
      "         4.2286e-02,  1.1649e-01,  5.9543e-02,  9.4889e-02, -1.0619e-02,\n",
      "         7.2903e-02,  5.5307e-02, -6.4315e-02, -1.2029e-01, -5.1880e-02,\n",
      "         2.4200e-02,  1.4573e-01, -4.6642e-02, -1.1980e-01, -1.6136e-01,\n",
      "        -9.8349e-02,  1.5268e-01,  2.4369e-02,  2.0037e-02, -9.7579e-02,\n",
      "         1.3528e-01, -2.0026e-02, -7.7529e-02,  8.5495e-02, -3.3874e-02,\n",
      "        -8.8076e-02, -1.4844e-01,  1.0570e-01, -1.1015e-01,  8.7693e-02,\n",
      "        -1.1229e-01,  1.3818e-02, -6.7978e-03, -9.9353e-02, -7.7508e-02,\n",
      "         9.7468e-02,  1.1222e-01,  8.0912e-02,  1.0659e-01,  6.5080e-02,\n",
      "        -5.4259e-02, -9.8513e-04, -9.0794e-02,  7.2119e-02, -7.5593e-02,\n",
      "        -5.8814e-02, -5.9294e-02,  9.3503e-02,  3.7845e-02,  1.2243e-01,\n",
      "        -1.1167e-01,  5.5671e-02, -1.2620e-01, -1.1000e-01,  1.4894e-01,\n",
      "        -9.3180e-02, -5.8315e-02,  5.7442e-02, -9.2692e-02, -5.9926e-02,\n",
      "        -1.2390e-01, -3.3908e-02, -9.2469e-02,  1.1959e-01, -5.9556e-02,\n",
      "        -4.7242e-02, -1.0325e-01, -1.4281e-03, -1.4612e-02,  1.0147e-01,\n",
      "        -1.3365e-01,  3.8608e-02,  5.9428e-04,  8.3467e-02, -1.0063e-01,\n",
      "        -1.0854e-01,  7.1470e-02, -6.7038e-02,  6.0444e-02,  1.4407e-01],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0482,  0.0187, -0.0955,  0.1305,  0.1156,  0.0684, -0.0276,  0.0401,\n",
      "         0.1381,  0.1088, -0.1194,  0.0038,  0.1196,  0.0428, -0.0135,  0.0452,\n",
      "        -0.0419, -0.1059, -0.0776, -0.0270,  0.0733, -0.1081,  0.0959, -0.0785,\n",
      "        -0.0369, -0.1023,  0.0498,  0.0105,  0.0902, -0.1016, -0.0292,  0.0468,\n",
      "         0.0138,  0.0594,  0.0601,  0.0054,  0.1320,  0.0035, -0.0537,  0.0310,\n",
      "         0.0447,  0.1265, -0.0797, -0.0762, -0.1280, -0.0790,  0.0496,  0.1200,\n",
      "         0.0843, -0.0830, -0.0430, -0.0360,  0.1188, -0.0297,  0.0651,  0.0003,\n",
      "        -0.0833,  0.0434, -0.0628, -0.1077, -0.1002, -0.1184,  0.0606,  0.1344,\n",
      "        -0.0075,  0.0903, -0.0058,  0.0937,  0.0742, -0.0742,  0.0291,  0.1042,\n",
      "        -0.1097,  0.0144, -0.1025,  0.0370,  0.0468, -0.0933,  0.1049,  0.0207,\n",
      "         0.0168, -0.1105,  0.0833,  0.1265, -0.0171, -0.0761,  0.1155,  0.0247,\n",
      "         0.0596,  0.0139, -0.0342,  0.0238,  0.1323, -0.0479,  0.0896,  0.0323,\n",
      "        -0.1188,  0.0025, -0.1433,  0.0169, -0.0868,  0.0181,  0.1527,  0.0646,\n",
      "         0.0882, -0.1585, -0.1053, -0.1326,  0.1011, -0.1354,  0.1194,  0.0048,\n",
      "        -0.1128,  0.0642,  0.0692,  0.1139, -0.0405, -0.1309,  0.0642, -0.0121,\n",
      "        -0.0610,  0.0184,  0.0329,  0.1412,  0.0189,  0.0926,  0.0726, -0.0196,\n",
      "        -0.1262,  0.0106,  0.0949,  0.0208,  0.1071, -0.1041, -0.1475, -0.0794,\n",
      "         0.0938, -0.0357, -0.0738, -0.1536, -0.0018,  0.0935, -0.0660, -0.0071,\n",
      "        -0.0309, -0.0208, -0.0511, -0.1103,  0.0890, -0.1030, -0.0778,  0.0223,\n",
      "         0.0956, -0.1029, -0.0863,  0.1350, -0.0069, -0.0602, -0.1172,  0.0443,\n",
      "        -0.0553,  0.0211,  0.1189,  0.0338,  0.1126, -0.0475, -0.0918, -0.0744,\n",
      "         0.1391,  0.0451,  0.1132, -0.0792,  0.0780, -0.0969,  0.0303,  0.0710,\n",
      "        -0.0046, -0.0982,  0.1094,  0.0196,  0.0695, -0.0742,  0.0352,  0.0323,\n",
      "        -0.0438,  0.0515,  0.0693,  0.0533,  0.0473, -0.0085,  0.0151, -0.1257,\n",
      "        -0.1149,  0.1012,  0.1060, -0.0918,  0.0515,  0.0388, -0.0248,  0.1092],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0904,  0.1125,  0.0473,  ..., -0.1136,  0.0372,  0.0461],\n",
      "        [-0.0712,  0.0641,  0.0236,  ..., -0.1095, -0.0712,  0.1005],\n",
      "        [-0.0475,  0.1554,  0.0661,  ..., -0.0432,  0.1451,  0.1094],\n",
      "        ...,\n",
      "        [ 0.0967, -0.0083,  0.0595,  ..., -0.0421,  0.0337,  0.0934],\n",
      "        [-0.0272,  0.1262,  0.0067,  ..., -0.0837,  0.0943,  0.0924],\n",
      "        [-0.1065, -0.0296,  0.0247,  ..., -0.0893, -0.0328,  0.0707]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0963,  0.0277, -0.1441,  ...,  0.0290, -0.0196,  0.1578],\n",
      "        [-0.1110,  0.1058,  0.0055,  ...,  0.0756, -0.0634, -0.0104],\n",
      "        [-0.0252,  0.0004, -0.1478,  ...,  0.0948,  0.0510, -0.0214],\n",
      "        ...,\n",
      "        [-0.1059, -0.0749,  0.1274,  ...,  0.0912,  0.1193, -0.0987],\n",
      "        [ 0.0725,  0.0862, -0.0142,  ..., -0.1212,  0.0497,  0.0228],\n",
      "        [-0.0505,  0.1271, -0.0630,  ...,  0.0065, -0.0620,  0.0028]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0901,  0.0694, -0.1138, -0.1113, -0.0059,  0.0843,  0.0678,  0.0471,\n",
      "         0.1613,  0.0153,  0.1055, -0.1233, -0.0142, -0.0813,  0.0068,  0.0387,\n",
      "         0.0776,  0.0986,  0.0958,  0.0249,  0.0102, -0.1304, -0.0650,  0.0435,\n",
      "         0.0902,  0.0207,  0.1220, -0.0696, -0.0324,  0.1267,  0.0009, -0.1198,\n",
      "         0.0906, -0.0382,  0.1624,  0.1540,  0.0605,  0.1440,  0.0447,  0.0820,\n",
      "        -0.0140,  0.0857,  0.0976,  0.0355,  0.0087,  0.0321, -0.0837, -0.0590,\n",
      "         0.0140,  0.1065, -0.0500,  0.0676,  0.0266, -0.0978, -0.0426,  0.0480,\n",
      "        -0.1119, -0.0974,  0.0627,  0.0872, -0.1366,  0.1169, -0.0387,  0.1190,\n",
      "        -0.1145, -0.0128, -0.0672,  0.0801,  0.0532,  0.1396,  0.1349, -0.0903,\n",
      "         0.1055, -0.0179, -0.1185,  0.0910,  0.0130,  0.0463,  0.0797, -0.0717,\n",
      "         0.0870, -0.0651, -0.0999,  0.1601,  0.0951,  0.0414, -0.1190, -0.0614,\n",
      "         0.1144,  0.1000,  0.1399,  0.0839, -0.0507,  0.0098,  0.0822,  0.1169,\n",
      "         0.1637, -0.0120,  0.0999,  0.1210, -0.0060, -0.0092, -0.0984, -0.0724,\n",
      "         0.0483, -0.0343, -0.1516, -0.1591,  0.0041,  0.0366,  0.0935,  0.0629,\n",
      "        -0.0467, -0.1120,  0.1320,  0.1145, -0.1097,  0.0857, -0.0884,  0.0979,\n",
      "         0.0047, -0.0274,  0.0996, -0.1176,  0.0579, -0.0717, -0.0025,  0.0899,\n",
      "        -0.0806, -0.0226,  0.0543, -0.1154,  0.1208,  0.0084, -0.0999,  0.0541,\n",
      "         0.1534,  0.0913, -0.0284,  0.0953,  0.1332, -0.0090,  0.0985,  0.1225,\n",
      "         0.1331,  0.0188,  0.0130,  0.0500, -0.0328,  0.1255, -0.0421, -0.0803,\n",
      "        -0.0552, -0.0608,  0.0367,  0.0852, -0.0324,  0.1492,  0.1345,  0.0593,\n",
      "        -0.0711, -0.1270, -0.1044, -0.1122, -0.0535,  0.0391, -0.1061,  0.0733,\n",
      "         0.1019,  0.0772,  0.0755, -0.0441, -0.1144,  0.1564, -0.1122, -0.0925,\n",
      "         0.1565,  0.0749, -0.0364, -0.1083, -0.0925,  0.0799, -0.0193, -0.0575,\n",
      "         0.0613, -0.0175,  0.0979, -0.0525, -0.0538,  0.1265,  0.0466, -0.0373,\n",
      "         0.1298,  0.1446, -0.1040,  0.0208,  0.1054,  0.1288, -0.1037, -0.0365],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0091, -0.0225, -0.1159,  0.0773,  0.0125, -0.0030, -0.1020, -0.0126,\n",
      "        -0.1155, -0.1106,  0.0597, -0.0488, -0.0791,  0.1127, -0.1174,  0.0775,\n",
      "        -0.0039,  0.0056,  0.1240,  0.0128,  0.1297, -0.0336, -0.1202, -0.0816,\n",
      "         0.0988, -0.0753,  0.0338, -0.0279, -0.0416,  0.1116, -0.1065, -0.0782,\n",
      "         0.1167,  0.1156, -0.1068,  0.0204,  0.1581,  0.1380, -0.0047, -0.0092,\n",
      "        -0.0131, -0.0861, -0.0629,  0.1473,  0.1281, -0.0380, -0.0585, -0.0603,\n",
      "         0.0914,  0.0915, -0.0094,  0.0159,  0.1086, -0.0418,  0.0191,  0.1145,\n",
      "        -0.0054, -0.0639, -0.0352,  0.0622,  0.0850, -0.0301,  0.0733,  0.0055,\n",
      "         0.0577,  0.0475, -0.0802, -0.0724,  0.0326, -0.0808, -0.1149, -0.1019,\n",
      "         0.0978,  0.1295, -0.0700,  0.1423, -0.0885,  0.1175,  0.0049,  0.1348,\n",
      "         0.1272,  0.0727, -0.0463, -0.0939,  0.0454, -0.0865,  0.0130,  0.0336,\n",
      "         0.0667,  0.0064,  0.0998, -0.0979, -0.0462, -0.0335,  0.0823, -0.0124,\n",
      "         0.0016, -0.0671, -0.0601, -0.0198, -0.0009,  0.0510, -0.1018,  0.0901,\n",
      "        -0.1378, -0.0176, -0.1450,  0.0667, -0.0611, -0.0208,  0.1296,  0.0207,\n",
      "         0.0545, -0.1258, -0.0674, -0.0285, -0.0634,  0.0026, -0.0129, -0.1114,\n",
      "         0.0453,  0.0460, -0.0396,  0.0865, -0.1080, -0.0419, -0.0466, -0.0300,\n",
      "        -0.0054, -0.1218,  0.1127,  0.0048, -0.1196,  0.0889, -0.0264,  0.1532,\n",
      "        -0.0410,  0.0039, -0.0823, -0.0549,  0.0697,  0.0749,  0.1079, -0.0457,\n",
      "        -0.1068, -0.1271, -0.1086,  0.0482,  0.1582,  0.1129,  0.1426, -0.1155,\n",
      "        -0.0557,  0.1400, -0.0900,  0.1047,  0.0852,  0.0327,  0.0764, -0.0948,\n",
      "         0.0401, -0.0799,  0.1533, -0.0422,  0.0884,  0.0429, -0.1096, -0.0644,\n",
      "         0.0893,  0.1493, -0.1200, -0.1212, -0.1042,  0.0528, -0.0976, -0.0403,\n",
      "         0.0189, -0.0230, -0.0130, -0.0593,  0.0134,  0.1465, -0.0949,  0.0681,\n",
      "         0.0419,  0.0779,  0.0137,  0.1185,  0.0481, -0.0798,  0.0990, -0.0375,\n",
      "         0.0030, -0.1093, -0.0102,  0.0300,  0.1527, -0.0890, -0.0554, -0.1032],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0628,  0.0048, -0.0386, -0.0254, -0.0965, -0.0550,  0.0409,  0.0370,\n",
      "          0.0633, -0.0529, -0.0264,  0.0807,  0.0319, -0.0276, -0.0812,  0.0020,\n",
      "          0.0696, -0.0397,  0.0344,  0.0063, -0.0168, -0.0034, -0.0906, -0.0455,\n",
      "         -0.0796, -0.0122, -0.0786, -0.0020, -0.0600, -0.1008, -0.1074,  0.0183,\n",
      "          0.0292, -0.0616, -0.1016, -0.0268, -0.0880, -0.0802, -0.0625, -0.0953,\n",
      "          0.0661,  0.0147,  0.0560,  0.0021, -0.0687, -0.0292,  0.0107, -0.0012,\n",
      "          0.0125, -0.0678,  0.0640, -0.1157, -0.0187,  0.0588,  0.0343, -0.0544,\n",
      "         -0.0807, -0.0957,  0.0757,  0.0234, -0.0886, -0.0085, -0.0534, -0.0180,\n",
      "          0.0543, -0.0440, -0.1031, -0.0012, -0.0300, -0.0603, -0.1033, -0.1147,\n",
      "         -0.0338,  0.0685,  0.0303, -0.0552,  0.0552,  0.0774,  0.0621, -0.0534,\n",
      "          0.0611, -0.0778, -0.0432,  0.0242, -0.0087,  0.0564,  0.0464, -0.0798,\n",
      "          0.0732,  0.0747, -0.0211, -0.1074,  0.0051, -0.0149,  0.0018,  0.0680,\n",
      "         -0.0890, -0.0003,  0.0122, -0.1096],\n",
      "        [ 0.0100, -0.0464,  0.0035,  0.0724, -0.0727,  0.0263, -0.0674, -0.0740,\n",
      "         -0.1030, -0.0207,  0.0325, -0.1048, -0.0458, -0.0175,  0.0437, -0.1128,\n",
      "         -0.0531, -0.1133, -0.0423, -0.1163, -0.0239, -0.0826, -0.0139,  0.0259,\n",
      "         -0.1023, -0.1068, -0.0584, -0.0469, -0.0080, -0.1066,  0.0600,  0.0493,\n",
      "          0.0549,  0.0423,  0.0554,  0.0388,  0.0518, -0.0710, -0.0760,  0.0693,\n",
      "         -0.0792,  0.0706,  0.0095,  0.0160, -0.0939, -0.0869, -0.0500,  0.0401,\n",
      "         -0.0116,  0.0173, -0.0858, -0.0189,  0.0350, -0.0595,  0.0116, -0.0143,\n",
      "          0.0625, -0.1144, -0.0482, -0.0073,  0.0740, -0.0912, -0.0085,  0.0387,\n",
      "         -0.0241,  0.0830,  0.0428,  0.0331, -0.0894, -0.0590, -0.0335, -0.1171,\n",
      "          0.0735,  0.0796, -0.0893, -0.0615,  0.0808, -0.0305,  0.0443, -0.0443,\n",
      "         -0.0048, -0.0753,  0.0692, -0.0434, -0.1150, -0.0227, -0.1067,  0.0082,\n",
      "         -0.0869, -0.1098,  0.0070,  0.0531, -0.0217,  0.0172, -0.0668, -0.0017,\n",
      "         -0.0173,  0.0583, -0.0535,  0.0054],\n",
      "        [ 0.0185, -0.0091,  0.0719, -0.0868,  0.0601,  0.0348,  0.0770, -0.0515,\n",
      "          0.0311, -0.0892,  0.0206, -0.0430, -0.0145,  0.0475, -0.0098,  0.0476,\n",
      "          0.0145, -0.0772, -0.0086,  0.0796,  0.0493, -0.0745, -0.0019,  0.0135,\n",
      "         -0.0472,  0.0127,  0.0706,  0.0728, -0.0687, -0.0796, -0.0416, -0.0756,\n",
      "         -0.1013, -0.1042, -0.1058, -0.0502, -0.0220,  0.0053, -0.1097,  0.0621,\n",
      "         -0.1023, -0.0717,  0.0633,  0.0693,  0.0562, -0.0663,  0.0076, -0.0457,\n",
      "          0.0318, -0.0133,  0.0036, -0.0002,  0.0186, -0.0235,  0.0677, -0.0392,\n",
      "         -0.1150, -0.0846,  0.0120,  0.0522,  0.0741,  0.0349,  0.0643, -0.1051,\n",
      "         -0.0206,  0.0352,  0.0141, -0.1016, -0.0214,  0.0288, -0.0884, -0.0877,\n",
      "          0.0147,  0.0044, -0.0024,  0.0544,  0.0571, -0.0252,  0.0126, -0.0373,\n",
      "          0.0542, -0.0587,  0.0720,  0.0625,  0.0270, -0.0416,  0.0802,  0.0712,\n",
      "         -0.0206,  0.0460,  0.0298, -0.0465,  0.0735, -0.0609,  0.0093, -0.0644,\n",
      "         -0.0863,  0.0377,  0.0494,  0.0104],\n",
      "        [-0.0926, -0.0587, -0.0889, -0.0850,  0.0803,  0.0590,  0.0202, -0.0717,\n",
      "         -0.0724, -0.0301, -0.0040, -0.1107,  0.0527,  0.0395,  0.0346, -0.0329,\n",
      "          0.0259,  0.0352,  0.0782, -0.0110,  0.0525, -0.1069,  0.0372, -0.0967,\n",
      "         -0.0882, -0.0985,  0.0169,  0.0203,  0.0560, -0.0844,  0.0023, -0.1142,\n",
      "         -0.0435, -0.0447,  0.0141, -0.0339,  0.0039, -0.0872, -0.1127, -0.0907,\n",
      "          0.0495, -0.0669,  0.0121,  0.0802, -0.1102,  0.0839, -0.0008, -0.0509,\n",
      "         -0.0641,  0.0042, -0.0936,  0.0349,  0.0051, -0.0366, -0.0474,  0.0125,\n",
      "          0.0664, -0.0661, -0.0726, -0.0284, -0.0911,  0.0778, -0.0815, -0.0015,\n",
      "          0.0208,  0.0416,  0.0084, -0.0209, -0.1102,  0.0462, -0.0941, -0.0368,\n",
      "         -0.0069,  0.0472, -0.0954,  0.0048,  0.0406, -0.0376,  0.0693, -0.0773,\n",
      "         -0.0026, -0.0813,  0.0783, -0.0979,  0.0101, -0.0498, -0.0931,  0.0008,\n",
      "          0.0646,  0.0306, -0.1133, -0.1154,  0.0028,  0.0251,  0.0687,  0.0554,\n",
      "         -0.0394,  0.0497,  0.0093, -0.0424],\n",
      "        [ 0.0041,  0.0089, -0.1054,  0.0435, -0.0380,  0.0425, -0.0618,  0.0446,\n",
      "          0.0057, -0.0131, -0.0553, -0.0163, -0.0408, -0.0908,  0.0158,  0.0201,\n",
      "          0.0246,  0.0534,  0.0464, -0.1064,  0.0042, -0.0383, -0.0642,  0.0196,\n",
      "         -0.1030,  0.0091, -0.0049,  0.0493, -0.0660, -0.0128, -0.0776, -0.0875,\n",
      "          0.0543, -0.1137, -0.0302, -0.0647, -0.0429,  0.0133,  0.0366, -0.0240,\n",
      "          0.0265, -0.0811, -0.0310,  0.0598, -0.0836,  0.0357,  0.0733, -0.0427,\n",
      "          0.0760, -0.0090, -0.1142,  0.0286, -0.0376, -0.0383, -0.1081,  0.0690,\n",
      "          0.0444, -0.0540,  0.0080,  0.0635, -0.0018, -0.0802,  0.0615, -0.0810,\n",
      "         -0.0029, -0.0367, -0.0249, -0.0167,  0.0029, -0.0028,  0.0358, -0.1126,\n",
      "         -0.0554, -0.0771,  0.0435,  0.0286,  0.0645, -0.0832,  0.0028, -0.0051,\n",
      "         -0.0243,  0.0148, -0.0138,  0.0794,  0.0053, -0.0667, -0.0126,  0.0577,\n",
      "         -0.0847, -0.0707,  0.0363,  0.0140, -0.0172, -0.0247,  0.0620, -0.0517,\n",
      "         -0.0868, -0.0707,  0.0789, -0.0265],\n",
      "        [ 0.0484, -0.0727,  0.0305, -0.0713, -0.0642, -0.0850, -0.0977, -0.0890,\n",
      "         -0.0369, -0.0231,  0.0266, -0.1140, -0.0471, -0.0312, -0.0554,  0.0313,\n",
      "          0.0359,  0.0431, -0.0489,  0.0447, -0.0125, -0.0574,  0.0101, -0.0419,\n",
      "         -0.0022, -0.0729, -0.1035,  0.0483, -0.1100, -0.1137,  0.0372, -0.0421,\n",
      "         -0.1083, -0.0727,  0.0543, -0.0005,  0.0174, -0.0125, -0.0265, -0.0151,\n",
      "          0.0752, -0.1062, -0.0896, -0.1012, -0.1038,  0.0498,  0.0383,  0.0439,\n",
      "         -0.1033, -0.0725,  0.0581, -0.1079, -0.1161, -0.0165, -0.0002,  0.0601,\n",
      "          0.0476, -0.0957,  0.0231,  0.0350,  0.0764,  0.0432, -0.0933, -0.0626,\n",
      "          0.0201,  0.0591,  0.0713, -0.0209, -0.0337, -0.0498,  0.0704, -0.0704,\n",
      "         -0.0860,  0.0766,  0.0527,  0.0704, -0.1039,  0.0291, -0.0867,  0.0389,\n",
      "         -0.0367, -0.0933, -0.0004, -0.0169,  0.0530, -0.0249, -0.1120, -0.0547,\n",
      "          0.0789, -0.0256, -0.0640, -0.0375, -0.0940,  0.0604,  0.0234,  0.0466,\n",
      "          0.0362, -0.0168, -0.0515, -0.0924]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0700,  0.0018,  0.0339, -0.1088,  0.0273, -0.0732],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for value in model.parameters():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\penaldo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for data in Test:\n",
    "        data = Variable(data, volatile=True)\n",
    "        output = model(data)\n",
    "        result=output.data\n",
    "        result=(result>.16).float()\n",
    "        preds.append(result.numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.concatenate(preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"Dataset/sample_submission.csv\")\n",
    "sample_submission[classes] = y_test\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
